{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## BIBLIOTECAS IMPORTADAS ##\n",
    "\n",
    "Na célula abaixo estão todas as bibliotecas necessárias para o classificador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Célula para importação de bibliotecas e APIs\n",
    "\n",
    "\n",
    "#Conjunto de funções para trabalhar com arquivos\n",
    "import os\n",
    "import sys\n",
    "\n",
    "\n",
    "#Conjunto de funcoes para plot\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "#Conjunto de funcoes para estrair o pitch\n",
    "\n",
    "import platform\n",
    "if(platform.system() == 'Windows'):\n",
    "    import f0_praat_windows as f0_praat   #Função para estrair pitch windows\n",
    "if(platform.system() == 'Linux'):\n",
    "    import f0_praat as f0_praat\n",
    "import tgt        #Funções para ler arquivos TextGrid\n",
    "\n",
    "\n",
    "#Conjunto de funções matemáticas\n",
    "import numpy\n",
    "\n",
    "\n",
    "#Conjunto de funcoes auxiliares caso necessário\n",
    "import auxiliar_codes\n",
    "\n",
    "\n",
    "#Conjunto de funções para filtragem\n",
    "from scipy import signal\n",
    "from scipy.io import wavfile\n",
    "\n",
    "\n",
    "#Sci-kit learn\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_moons, make_circles, make_classification\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "#Para plot 3D caso necessário\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leitura e definição dos arquivo\n",
    "\n",
    "Definido os arquivos para execução das atividades. Existe uma definição de diretórios para Windows e Linux. Não é possível a utilização universal devido à execução do praat não entender diretórios relativos. Então dependendo do S.O. alterar a variável **dire** para os diretórios completos ao qual se situam-se os arquivos de áudios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Célula para lê os diretórios e arquivos a serem utilizados\n",
    "\n",
    "# The name of the audio file\n",
    "files = [];\n",
    "\n",
    "\n",
    "#The name of the directory of audio files\n",
    "#dire= \"../Audio_Files/Tiago\";\n",
    "dire_win = \"G:\\\\Dropbox\\\\IC\\\\Audio_Files\\\\Tiago\"; #diretorio tem que ser completo para o praat\n",
    "dire_linux = \"/home/tiagohbalves/Dropbox/IC/Audio_Files/Tiago\";\n",
    "dire_win_filter = \"G:\\\\Dropbox\\\\IC\\\\Audio_Files\\\\Tiago\\\\Filtrados\"; #diretorio tem que ser completo para o praat\n",
    "dire_linux_filter = \"/home/tiagohbalves/Dropbox/IC/Audio_Files/Tiago/Filtrados\";\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import platform\n",
    "if(platform.system() == 'Windows'):\n",
    "    dire = dire_win;  #Diretorio Windows\n",
    "    audio_filtrado = \"G:\\\\Dropbox\\\\IC\\\\Audio_Files\\\\Tiago\\\\Filtrados\\\\Audio_Track_2.wav\";\n",
    "if(platform.system() == 'Linux'):\n",
    "    audio_filtrado = \"/home/tiagohbalves/Dropbox/IC/Audio_Files/Tiago/Filtrados/Audio_Track_2.wav\";\n",
    "    dire = dire_linux; #Diretório Linux\n",
    "#\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for file in os.listdir(dire):\n",
    "    if file.endswith(\".wav\"):\n",
    "        files.append(\"/\"+file);\n",
    "\n",
    "files.sort();\n",
    "\n",
    "\n",
    "\n",
    "#audio_file=dire_afirm+files_perg[0];\n",
    "\n",
    "\n",
    "audio_file1 = dire+files[0];\n",
    "audio_file2 = dire+files[1];\n",
    "\n",
    "\n",
    "\n",
    "#tempo = numpy.loadtxt(open(\"../Dados/tempos_1.csv\",\"rb\"),delimiter=\",\");\n",
    "\n",
    "#Arquivo de text grid de ambos os arquivos de áudios\n",
    "tg = tgt.read_textgrid(\"../Audio_Files/Tiago/MARCACOES_PRAAT.TextGrid\");\n",
    "\n",
    "#tempo = tempo.astype(int);\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Marcacoes_praat = tg.get_tier_by_name('MARCACAO')\n",
    "\n",
    "F01a = Marcacoes_praat.get_annotations_with_text('F01a')\n",
    "F02a = Marcacoes_praat.get_annotations_with_text('F02a')\n",
    "F03a = Marcacoes_praat.get_annotations_with_text('F03a')\n",
    "F04a = Marcacoes_praat.get_annotations_with_text('F04a')\n",
    "F05a = Marcacoes_praat.get_annotations_with_text('F05a')\n",
    "F06a = Marcacoes_praat.get_annotations_with_text('F06a')\n",
    "F07a = Marcacoes_praat.get_annotations_with_text('F07a')\n",
    "F08a = Marcacoes_praat.get_annotations_with_text('F08a')\n",
    "F09a = Marcacoes_praat.get_annotations_with_text('F09a')\n",
    "F10a = Marcacoes_praat.get_annotations_with_text('F10a')\n",
    "F11a = Marcacoes_praat.get_annotations_with_text('F11a')\n",
    "F12a = Marcacoes_praat.get_annotations_with_text('F12a')\n",
    "F13a = Marcacoes_praat.get_annotations_with_text('F13a')\n",
    "F14a = Marcacoes_praat.get_annotations_with_text('F14a')\n",
    "F01b = Marcacoes_praat.get_annotations_with_text('F01b')\n",
    "F02b = Marcacoes_praat.get_annotations_with_text('F02b')\n",
    "F03b = Marcacoes_praat.get_annotations_with_text('F03b')\n",
    "F04b = Marcacoes_praat.get_annotations_with_text('F04b')\n",
    "F05b = Marcacoes_praat.get_annotations_with_text('F05b')\n",
    "F06b = Marcacoes_praat.get_annotations_with_text('F06b')\n",
    "F07b = Marcacoes_praat.get_annotations_with_text('F07b')\n",
    "F08b = Marcacoes_praat.get_annotations_with_text('F08b')\n",
    "F09b = Marcacoes_praat.get_annotations_with_text('F09b')\n",
    "F10b = Marcacoes_praat.get_annotations_with_text('F10b')\n",
    "F11b = Marcacoes_praat.get_annotations_with_text('F11b')\n",
    "F12b = Marcacoes_praat.get_annotations_with_text('F12b')\n",
    "F13b = Marcacoes_praat.get_annotations_with_text('F13b')\n",
    "F14b = Marcacoes_praat.get_annotations_with_text('F14b')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "i = 0;\n",
    "stimes = [];\n",
    "etimes = []\n",
    "\n",
    "for i in range(0,5):\n",
    "    stimes.append([[round(F01a[i].start_time,2)],[round(F02a[i].start_time,2)],[round(F03a[i].start_time,2)],[round(F04a[i].start_time,2)],[round(F05a[i].start_time,2)]\n",
    "                   ,[round(F06a[i].start_time,2)],[round(F07a[i].start_time,2)],[round(F08a[i].start_time,2)],[round(F09a[i].start_time,2)],[round(F10a[i].start_time,2)]\n",
    "                   ,[round(F11a[i].start_time,2)],[round(F12a[i].start_time,2)],[round(F13a[i].start_time,2)],[round(F14a[i].start_time,2)],[round(F01b[i].start_time,2)]\n",
    "                   ,[round(F02b[i].start_time,2)],[round(F03b[i].start_time,2)],[round(F04b[i].start_time,2)],[round(F05b[i].start_time,2)]\n",
    "                   ,[round(F06b[i].start_time,2)],[round(F07b[i].start_time,2)],[round(F08b[i].start_time,2)],[round(F09b[i].start_time,2)],[round(F10b[i].start_time,2)]\n",
    "                   ,[round(F11b[i].start_time,2)],[round(F12b[i].start_time,2)],[round(F13b[i].start_time,2)],[round(F14b[i].start_time,2)]])\n",
    "    etimes.append([[round(F01a[i].end_time,2)],[round(F02a[i].end_time,2)],[round(F03a[i].end_time,2)],[round(F04a[i].end_time,2)],[round(F05a[i].end_time,2)]\n",
    "                   ,[round(F06a[i].end_time,2)],[round(F07a[i].end_time,2)],[round(F08a[i].end_time,2)],[round(F09a[i].end_time,2)],[round(F10a[i].end_time,2)]\n",
    "                   ,[round(F11a[i].end_time,2)],[round(F12a[i].end_time,2)],[round(F13a[i].end_time,2)],[round(F14a[i].end_time,2)],[round(F01b[i].end_time,2)]\n",
    "                   ,[round(F02b[i].end_time,2)],[round(F03b[i].end_time,2)],[round(F04b[i].end_time,2)],[round(F05b[i].end_time,2)],[round(F06b[i].end_time,2)]\n",
    "                   ,[round(F07b[i].end_time,2)],[round(F08b[i].end_time,2)],[round(F09b[i].end_time,2)],[round(F10b[i].end_time,2)],[round(F11b[i].end_time,2)]\n",
    "                   ,[round(F12b[i].end_time,2)],[round(F13b[i].end_time,2)],[round(F14b[i].end_time,2)]])     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "S = numpy.array(stimes);\n",
    "E = numpy.array(etimes);\n",
    "STimes = numpy.asmatrix(S);\n",
    "ETimes = numpy.asmatrix(E);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.6/site-packages/scipy/io/wavfile.py:267: WavFileWarning: Chunk (non-data) not understood, skipping it.\n",
      "  WavFileWarning)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "rate,audio_signal = wavfile.read(audio_file2);\n",
    "\n",
    "\n",
    "\n",
    "#Filtragem de Audio\n",
    "a,b  = signal.butter(8,[0,70],'bandstop', analog=True);\n",
    "signa_filter1 = signal.filtfilt(b, a, audio_signal);\n",
    "\n",
    "wavfile.write(audio_filtrado,rate,signa_filter1)\n",
    "\n",
    "\n",
    "#wave_output = wave.open(audio_filtrado, 'w');\n",
    "#audio_output = numpy.array_str(signa_filter1);\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44100"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The base rate\n",
    "srate = 100.0;\n",
    "\n",
    "# The pitch range to be used by the pitch extraction algorithm\n",
    "#pitch_range = (150, 500);\n",
    "#pitch_range = (40, 500);\n",
    "#pitch_range = (70, 350);\n",
    "pitch_range = (70,170);\n",
    "\n",
    "# Parameters for Praat's pitch extraction algorithm\n",
    "input_parms = {};\n",
    "input_parms[\"time_step\"]     = 1.0/srate;\n",
    "input_parms[\"pitch_floor\"]   = pitch_range[0];\n",
    "input_parms[\"pitch_ceiling\"] = pitch_range[1];\n",
    "\n",
    "\n",
    "#  Extract the F0 signal\n",
    "(f0_signal1,f0_time1,f0_parms1) = f0_praat.compute_f0_praat(audio_file1,input_parms);\n",
    "(f0_signal2,f0_time2,f0_parms2) = f0_praat.compute_f0_praat(audio_file2,input_parms);\n",
    "(f0_signal3,f0_time3,f0_parms3) = f0_praat.compute_f0_praat(audio_filtrado,input_parms);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21507072"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(audio_signal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  5.49412782e+32,   5.43229638e+32,   5.37022148e+32, ...,\n",
       "        -4.27327627e+31,  -4.54584746e+31,  -4.42454271e+31])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signa_filter1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21507072"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(signa_filter1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "data = [];\n",
    "data_fit = [];\n",
    "\n",
    "p01a = [];\n",
    "p02a = [];\n",
    "p03a = [];\n",
    "p04a = [];\n",
    "p05a = [];\n",
    "p06a = [];\n",
    "p07a = [];\n",
    "\n",
    "\n",
    "p01b = [];\n",
    "p02b = [];\n",
    "p03b = [];\n",
    "p04b = [];\n",
    "p05b = [];\n",
    "p06b = [];\n",
    "p07b = [];\n",
    "\n",
    "p1a_fit = [];\n",
    "p2a_fit = [];\n",
    "p3a_fit = [];\n",
    "p4a_fit = [];\n",
    "p5a_fit = [];\n",
    "p6a_fit = [];\n",
    "p7a_fit = [];\n",
    "\n",
    "p1b_fit = [];\n",
    "p2b_fit = [];\n",
    "p3b_fit = [];\n",
    "p4b_fit = [];\n",
    "p5b_fit = [];\n",
    "p6b_fit = [];\n",
    "p7b_fit = [];\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "t = numpy.arange(0.0,500.0,1/srate)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for i in range(0,28):\n",
    "    \n",
    "    \n",
    "    for j in range(0,5):\n",
    "\n",
    "\n",
    "\n",
    "        t1 = t[range(0,int(100*(ETimes[j,i] - STimes[j,i])))];\n",
    "        t2 = t1;\n",
    "\n",
    "\n",
    "        arr1 = f0_signal1[range(int(100*STimes[j,i]),int(100*ETimes[j,i]))];\n",
    "        arr2 = f0_signal2[range(int(100*STimes[j,i]),int(100*ETimes[j,i]))];\n",
    "        ex = [];\n",
    "        ex2 = [];\n",
    "        for k in range(0,len(arr1)):\n",
    "            if numpy.isnan(arr1[k]):\n",
    "                ex.append(k);\n",
    "            if numpy.isnan(arr2[k]):\n",
    "                ex2.append(k);\n",
    "\n",
    "        t1 = numpy.asarray(t1);\n",
    "        t2 = t1;\n",
    "        arr1 = numpy.asarray(arr1);\n",
    "        arr2 = numpy.asarray(arr2);\n",
    "        \n",
    "        arr1 = numpy.delete(arr1,ex);\n",
    "        #print(arr1);\n",
    "        arr2 = numpy.delete(arr2,ex2);\n",
    "        #print(arr2);\n",
    "        t1 = numpy.delete(t1,ex);\n",
    "        t2 = numpy.delete(t2,ex2);\n",
    "        \n",
    "        arr1_fit = arr1.reshape(-1,1);\n",
    "        arr1_fit = MinMaxScaler().fit_transform(arr1_fit);\n",
    "\n",
    "        arr2_fit = arr2.reshape(-1,1);\n",
    "        arr2_fit = MinMaxScaler().fit_transform(arr2_fit);\n",
    "\n",
    "        \n",
    "        p01a.append(numpy.polyfit(t1 ,arr1 ,1));\n",
    "        p02a.append(numpy.polyfit(t1 ,arr1 ,2));\n",
    "        p03a.append(numpy.polyfit(t1 ,arr1 ,3));\n",
    "        p04a.append(numpy.polyfit(t1 ,arr1 ,4));\n",
    "        p05a.append(numpy.polyfit(t1 ,arr1 ,5));\n",
    "        p06a.append(numpy.polyfit(t1 ,arr1 ,6));\n",
    "        p07a.append(numpy.polyfit(t1 ,arr1 ,7));\n",
    "        \n",
    "        p01b.append(numpy.polyfit(t2 ,arr2 ,1));\n",
    "        p02b.append(numpy.polyfit(t2 ,arr2 ,2));\n",
    "        p03b.append(numpy.polyfit(t2 ,arr2 ,3));\n",
    "        p04a.append(numpy.polyfit(t2 ,arr2 ,4));\n",
    "        p05b.append(numpy.polyfit(t2 ,arr2 ,5));\n",
    "        p06b.append(numpy.polyfit(t2 ,arr2 ,6));\n",
    "        p07b.append(numpy.polyfit(t2 ,arr2 ,7));\n",
    "\n",
    "\n",
    "        p1a_fit.append(numpy.polyfit(t1 ,arr1_fit ,1));\n",
    "        p2a_fit.append(numpy.polyfit(t1 ,arr1_fit ,2));\n",
    "        p3a_fit.append(numpy.polyfit(t1 ,arr1_fit ,3));\n",
    "        p4a_fit.append(numpy.polyfit(t1 ,arr1_fit ,4));\n",
    "        p5a_fit.append(numpy.polyfit(t1 ,arr1_fit ,5));\n",
    "        p6a_fit.append(numpy.polyfit(t1 ,arr1_fit ,6));\n",
    "        p7a_fit.append(numpy.polyfit(t1 ,arr1_fit ,7));\n",
    "        \n",
    "        p1b_fit.append(numpy.polyfit(t2 ,arr2_fit ,1));\n",
    "        p2b_fit.append(numpy.polyfit(t2 ,arr2_fit ,2));\n",
    "        p3b_fit.append(numpy.polyfit(t2 ,arr2_fit ,3));\n",
    "        p4b_fit.append(numpy.polyfit(t2 ,arr2_fit, 4));\n",
    "        p5b_fit.append(numpy.polyfit(t2 ,arr2_fit, 5));\n",
    "        p6b_fit.append(numpy.polyfit(t2 ,arr2_fit, 6));\n",
    "        p7b_fit.append(numpy.polyfit(t2 ,arr2_fit, 7));\n",
    "\n",
    "\n",
    "\n",
    "        #min_max_scaler = MinMaxScaler()\n",
    "        #data.append(arr);\n",
    "        #data_fit.append(arr_fit);\n",
    "        #data_fit1.append(min_max_scaler.fit_transform(arr));\n",
    "        \n",
    "        \n",
    "        plt.ylabel('F0');\n",
    "        plt.xlabel('Tempo(s)');\n",
    "        #t1 = t1 - numpy.min(t1);\n",
    "        t2 = t2 - numpy.min(t2);\n",
    "\n",
    "        plt.ylim(0,200);\n",
    "        plt.xlim(0,2);\n",
    "        \n",
    "        plt.plot(t2,arr2);\n",
    "    plt.grid(\"on\");\n",
    "    plt.title('Frase '+ str((i)+1))\n",
    "    #plt.show();\n",
    "    plt.savefig('../Figuras/F0s/F0_'+str(i+1)+'.pdf');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig2d = plt.figure(1,figsize=(30,40))\n",
    "#fig2d.add_subplot(10,i,1)\n",
    "p2d = numpy.asarray(p02a)\n",
    "\n",
    "fig2d.suptitle('Regressão primeira ordem sem Fit')\n",
    "\n",
    "\n",
    "fig2d.set_figwidth(7)\n",
    "fig2d.set_figheight(50)\n",
    "\n",
    "\n",
    "\n",
    "for j in range(0,14):\n",
    "    splt = fig2d.add_subplot(10,j+1,1);\n",
    "    splt.set_ylabel('Ordem 3');\n",
    "    splt.set_xlabel('Ordem 2');\n",
    "    #plt.xlim(-50,150);\n",
    "    #plt.ylim(-50,150);\n",
    "    for i in range(0,5):\n",
    "\n",
    "        plt.plot(p2d[i+(j*5),1],p2d[i+(j*5),2],'r^')\n",
    "        plt.plot(p2d[i+70+(j*5),1],p2d[i+70+(j*5),2],'bo')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "fig2d = plt.figure(1,figsize=(30,40))\n",
    "#fig2d.add_subplot(10,i,1)\n",
    "p2d = numpy.asarray(p01a)\n",
    "\n",
    "fig2d.suptitle('Regressão primeira ordem sem Fit')\n",
    "\n",
    "\n",
    "fig2d.set_figwidth(7)\n",
    "fig2d.set_figheight(50)\n",
    "\n",
    "\n",
    "\n",
    "for j in range(0,14):\n",
    "    splt = fig2d.add_subplot(10,j+1,1);\n",
    "    splt.set_ylabel('Ordem 2');\n",
    "    splt.set_ylabel('Ordem 1');\n",
    "    plt.xlim(-50,20);\n",
    "    plt.ylim(-100,150);\n",
    "    for i in range(0,5):\n",
    "\n",
    "        plt.plot(p2d[i+(j*10),0],p2d[i+(j*10),1],'r^')\n",
    "        plt.plot(p2d[i+5+(j*10),0],p2d[i+5+(j*10),1],'bo')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig2d_fit = plt.figure(2)\n",
    "#fig2d_fit.add_subplot(10,i,1)\n",
    "#p2d_fit = numpy.asarray(p1a_fit)\n",
    "p2d_fit = numpy.asarray(p2a_fit)\n",
    "\n",
    "fig2d_fit.suptitle('Regressão primeira ordem com Fit')\n",
    "\n",
    "\n",
    "fig2d_fit.set_figwidth(7)\n",
    "fig2d_fit.set_figheight(40)\n",
    "\n",
    "for j in range(0,14):\n",
    "    splt = fig2d_fit.add_subplot(10,j+1,1)\n",
    "    splt.set_ylabel('Ordem 1');\n",
    "    splt.set_xlabel('Deslocamento');\n",
    "    plt.ylim(-0.1,1.5);\n",
    "    plt.xlim(-2,2.6);\n",
    "    for i in range(0,5):\n",
    "\n",
    "        plt.plot(p2d_fit[i+(j*10),1],p2d_fit[i+(j*10),2],'r^')\n",
    "        plt.plot(p2d_fit[i+5+(j*10),1],p2d_fit[i+5+(j*10),2],'bo')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "fig3d = plt.figure(3,figsize=(10,40))\n",
    "\n",
    "\n",
    "fig3d.suptitle('Regressão terceira ordem com Fit')\n",
    "\n",
    "\n",
    "p3d_fit = numpy.asarray(p2a_fit)\n",
    "\n",
    "\n",
    "for j in range(0,14):\n",
    "    ax = fig3d.add_subplot(14,1,(j+1),projection='3d')\n",
    "    \n",
    "    #ax.view_init(0,90);\n",
    "    ax.set_xlim(-20,10);\n",
    "    ax.set_ylim(-10,40);\n",
    "    ax.set_zlim(-2,2);\n",
    "     \n",
    "    \n",
    "    ax.set_xlabel('Deslocamento')\n",
    "    ax.set_ylabel('Ordem 1');\n",
    "    ax.set_zlabel('Ordem 2');\n",
    "\n",
    "    for i in range(0,5):\n",
    "\n",
    "        ax.scatter(p3d_fit[i+(j*10),0],p3d_fit[i+(j*10),1],p3d_fit[i+(j*10),2],c = 'b',marker = '^')\n",
    "        ax.scatter(p3d_fit[i+5+(j*10),0],p3d_fit[i+5+(j*10),1],p3d_fit[i+(j*10)+5,2],c= 'r',marker = 'o')\n",
    "        \n",
    "        ax.set_xlabel('Deslocamento')\n",
    "        ax.set_ylabel('Ordem 1')\n",
    "        ax.set_zlabel('Ordem 2')\n",
    "\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig3d = plt.figure(3,figsize=(10,80))\n",
    "\n",
    "\n",
    "fig3d.suptitle('Regressão terceira ordem sem Fit')\n",
    "\n",
    "\n",
    "p3d = numpy.asarray(p02a)\n",
    "\n",
    "\n",
    "for j in range(0,14):\n",
    "    ax = fig3d.add_subplot(14,1,(j+1),projection='3d')\n",
    "    \n",
    "    ax.view_init(30,135);\n",
    "    \n",
    "    ax.set_xlabel('Deslocamento')\n",
    "    ax.set_ylabel('Ordem 1');\n",
    "    ax.set_zlabel('Ordem 2');\n",
    "    ax.set_xlim(-380,90);\n",
    "    ax.set_ylim(-100,130);\n",
    "    ax.set_zlim(-150,450);\n",
    "    ax.set_axis_on()\n",
    "    \n",
    "    for i in range(0,5):\n",
    "\n",
    "        ax.scatter(p3d[i+(j*10),0],p3d[i+(j*10),1],p3d[i+(j*10),2],c = 'b',marker = '^')\n",
    "        ax.scatter(p3d[i+5+(j*10),0],p3d[i+5+(j*10),1],p3d[i+(j*10)+5,2],c= 'r',marker = 'o')\n",
    "        \n",
    "       \n",
    "\n",
    "        \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p4da = numpy.asarray(p03a)\n",
    "p4db = numpy.asarray(p03a)\n",
    "p4da_fit = numpy.asarray(p3a_fit)\n",
    "p4db_fit = numpy.asarray(p3b_fit)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(0,10):\n",
    "    print(p2d[i*14])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Nomes = [\"Ele estará ocupado?\",\n",
    "\"Você está disponível?\",\n",
    "\"Choverá hoje?\",\n",
    "\"Está chovendo?\",\n",
    "\"Ele está bem?\",\n",
    "\"Esá fazendo sol?\",\n",
    "\"A prova será semana que vem?\",\n",
    "\"O carro foi vendido?\",\n",
    "\"O compromisso foi adiado?\",\n",
    "\"A atividade acabou?\",\n",
    "\"O café está quente?\",\n",
    "\"A porta esta trancada?\",\n",
    "\"Ele virá hoje?\",\n",
    "\"Você leu o livro?\",\n",
    "\"Ele estará ocupado.\",\n",
    "\"Você está disponivel.\",\n",
    "\"Choverá hoje.\",\n",
    "\"Está chovendo.\",\n",
    "\"Ele esta bem.\",\n",
    "\"Está fazendo sol.\",\n",
    "\"A prova será semana que vem.\",\n",
    "\"O carro foi vendido.\",\n",
    "\"O compromisso foi adiado.\",\n",
    "\"A atividade acabou.\",\n",
    "\"O café está quente.\",\n",
    "\"A porta esta trancada.\",\n",
    "\"Ele virá hoje.\",\n",
    "\"Você leu o livro.\"]\n",
    "\n",
    "pos = numpy.random.permutation(140);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(0,140):\n",
    "    j = pos[i]%28;\n",
    "    print(\"    \\\\begin{frame}\")\n",
    "    print(\"        \\\\begin{itemize}\")\n",
    "    print(\"            \\\\item \"+Nomes[pos[i]%28])\n",
    "    print(\"        \\end{itemize}\")\n",
    "    print(\"    \\\\end{frame}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = numpy.zeros((140,1));\n",
    "X = numpy.asarray(p02a)\n",
    "X1 = numpy.asarray(p02b)\n",
    "X2 = numpy.asarray(p2a_fit)\n",
    "X3 = numpy.asarray(p2b_fit)\n",
    "\n",
    "\n",
    "for i in range(0,14):\n",
    "    for j in range(0,5):\n",
    "        y[i*10+(j)] = 1;\n",
    "        y[i*10+5+(j)] = 0\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datasets = [];\n",
    "for i in range(0,14):\n",
    "    aux1 = numpy.zeros((10,2));\n",
    "    aux2 = numpy.zeros((10,2));\n",
    "    aux3 = numpy.zeros((10,2));\n",
    "    aux4 = numpy.zeros((10,2));\n",
    "    auxy = numpy.zeros((10,1));\n",
    "    linearly_separable1 = [];\n",
    "    linearly_separable2 = [];\n",
    "    linearly_separable3 = [];\n",
    "    linearly_separable4 = [];\n",
    "    \n",
    "    for j in range(0,5):\n",
    "        aux1[j] = X[i+(j*5),1],X[i+(j*5),2];\n",
    "        aux1[j+5] = X[i+70+(j*5),1],X[i+70+(j*5),2];\n",
    "        aux2[j] = X1[i+(j*5),1],X1[i+(j*5),2];\n",
    "        aux2[j+5] = X1[i+70+(j*5),1],X1[i+70+(j*5),2];\n",
    "        aux3[j] = X2[i+(j*5),1],X2[i+(j*5),2];\n",
    "        aux3[j+5] = X2[i+70+(j*5),1],X2[i+70+(j*5),2];\n",
    "        aux4[j] = X3[i+(j*5),1],X3[i+(j*5),2];\n",
    "        aux4[j+5] = X3[i+70+(j*5),1],X3[i+70+(j*5),2];\n",
    "        auxy[j] = 0;\n",
    "        auxy[j+5] = 1;\n",
    "        \n",
    "    linearly_separable1 = (aux1, auxy);\n",
    "    linearly_separable2 = (aux2, auxy);\n",
    "    linearly_separable3 = (aux3, auxy);\n",
    "    linearly_separable4 = (aux4, auxy);\n",
    "    \n",
    "    datasets.append(linearly_separable1);\n",
    "    datasets.append(linearly_separable2);\n",
    "    datasets.append(linearly_separable3);\n",
    "    datasets.append(linearly_separable4);\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "h = .02  # step size in the mesh\n",
    "\n",
    "a = numpy.logspace(-5, 3, 5)\n",
    "names = []\n",
    "\n",
    "alphas = numpy.logspace(-5, 3, 5)\n",
    "\n",
    "for i in alphas:\n",
    "    names.append('alpha ' + str(i))\n",
    "\n",
    "classifiers = []\n",
    "\n",
    "for i in alphas:\n",
    "    classifiers.append(MLPClassifier(alpha=i, random_state=1))\n",
    "\n",
    "\n",
    "\n",
    "figure = plt.figure(figsize=(17,156))\n",
    "i = 1\n",
    "# iterate over datasets\n",
    "for X, y in datasets:\n",
    "    # preprocess dataset, split into training and test part\n",
    "    X = StandardScaler().fit_transform(X)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.4)\n",
    "\n",
    "    x_min, x_max = X[:, 0].min() - .5, X[:, 0].max() + .5\n",
    "    y_min, y_max = X[:, 1].min() - .5, X[:, 1].max() + .5\n",
    "    xx, yy = numpy.meshgrid(numpy.arange(x_min, x_max, h),\n",
    "                         numpy.arange(y_min, y_max, h))\n",
    "\n",
    "    # just plot the dataset first\n",
    "    cm = plt.cm.RdBu\n",
    "    cm_bright = ListedColormap(['#FF0000', '#0000FF'])\n",
    "    ax = plt.subplot(len(datasets), len(classifiers) + 1, i)\n",
    "    # Plot the training points\n",
    "    ax.scatter(X_train[:, 0], X_train[:, 1], c=y_train, cmap=cm_bright)\n",
    "    # and testing points\n",
    "    ax.scatter(X_test[:, 0], X_test[:, 1], c=y_test, cmap=cm_bright, alpha=0.6)\n",
    "    ax.set_xlim(xx.min(), xx.max())\n",
    "    ax.set_ylim(yy.min(), yy.max())\n",
    "    ax.set_xticks(())\n",
    "    ax.set_yticks(())\n",
    "    i += 1\n",
    "\n",
    "    # iterate over classifiers\n",
    "    for name, clf in zip(names, classifiers):\n",
    "        ax = plt.subplot(len(datasets), len(classifiers) + 1, i)\n",
    "        clf.fit(X_train, y_train)\n",
    "        score = clf.score(X_test, y_test)\n",
    "\n",
    "        # Plot the decision boundary. For that, we will assign a color to each\n",
    "        # point in the mesh [x_min, x_max]x[y_min, y_max].\n",
    "        if hasattr(clf, \"decision_function\"):\n",
    "            Z = clf.decision_function(numpy.c_[xx.ravel(), yy.ravel()])\n",
    "        else:\n",
    "            Z = clf.predict_proba(numpy.c_[xx.ravel(), yy.ravel()])[:, 1]\n",
    "\n",
    "        # Put the result into a color plot\n",
    "        Z = Z.reshape(xx.shape)\n",
    "        ax.contourf(xx, yy, Z, cmap=cm, alpha=.8)\n",
    "\n",
    "        # Plot also the training points\n",
    "        ax.scatter(X_train[:, 0], X_train[:, 1], c=y_train, cmap=cm_bright)\n",
    "        # and testing points\n",
    "        ax.scatter(X_test[:, 0], X_test[:, 1], c=y_test, cmap=cm_bright,\n",
    "                   alpha=0.6)\n",
    "\n",
    "        ax.set_xlim(xx.min(), xx.max())\n",
    "        ax.set_ylim(yy.min(), yy.max())\n",
    "        ax.set_xticks(())\n",
    "        ax.set_yticks(())\n",
    "        ax.set_title(name)\n",
    "        ax.text(xx.max() - .3, yy.min() + .3, ('%.2f' % score).lstrip('0'),\n",
    "                size=15, horizontalalignment='right')\n",
    "        i += 1\n",
    "\n",
    "figure.subplots_adjust(left=.02, right=.98)\n",
    "plt.savefig(\"../Figuras/Resultados/Classificador.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
